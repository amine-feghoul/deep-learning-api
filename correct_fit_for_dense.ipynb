{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "b03cEQVN5Lm9",
    "outputId": "effd94ac-934e-447d-f1af-d7c5664cda41"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0A2b9BHC1A18"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import cv2\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "F7BrAToJbtey",
    "outputId": "b94d0f39-e946-4d8d-c0ba-6b456b88cfb3"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"melanoma.jpeg\",cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.show()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWA6SHUb1GNO"
   },
   "outputs": [],
   "source": [
    "class sequential(): \n",
    "  def __init__(self,):\n",
    "    self.output_shape = ()\n",
    "    self.Graph = []\n",
    "  def add(self,Object):\n",
    "    self.Graph.append(Object)\n",
    "    print(self.Graph)\n",
    "    self.output_shape =  Object.output_shape(    num_filters = Object.num_filters ,\n",
    "                                                 filter_size = Object.filter_size ,\n",
    "                                                 input_shape = Object.input_shape \n",
    "                                                 ) \n",
    "   \n",
    "  def cnn(self,num_filters,filter_size,input_shape = None):\n",
    "    if(input_shape == None):\n",
    "      if(len(self.Graph)== 0):\n",
    "        raise(\"the operations graph in empty\")\n",
    "      else:\n",
    "        temp = cnn(input_shape = self.output_shape,num_filters = num_filters,filter_size = filter_size)\n",
    "    else:\n",
    "      temp = cnn(input_shape = input_shape,num_filters = num_filters,filter_size = filter_size)\n",
    "    return temp\n",
    "  def max_pool(self,num_filters,filter_size,input_shape = None):\n",
    "    if(input_shape == None):\n",
    "      if(len(self.Graph)== 0):\n",
    "        raise ValueError(\"the operations graph in empty\")\n",
    "      else:\n",
    "        temp = maxPool(self.output_shape,filter_size)\n",
    "    else:\n",
    "      temp = maxPool(input_shape,filter_size)\n",
    "    return temp\n",
    "  def forawrdProp(self,image):\n",
    "   image = image\n",
    "   for i in self.Graph:\n",
    "      image = i.forwardProp(image)\n",
    "   self.out = image\n",
    "   return self.out \n",
    "  def dense(self,output_size,input_shape = None):\n",
    "    if(input_shape == None):\n",
    "      if(len(self.Graph)== 0):\n",
    "        raise(\"the operations graph in empty\")\n",
    "      else:\n",
    "        temp = dense(self.output_shape,output_size)\n",
    "    else:\n",
    "      temp = dense(input_shape,output_size)\n",
    "    return temp\n",
    "  def backProp(self,input_,lable,learn_rate):\n",
    "#       print(\"from back prop sequential\")\n",
    "      self.forawrdProp(input_)\n",
    "      delta = self.Graph[-1].backProp(lable = lable,learn_rate=learn_rate)\n",
    "      for i in range(2,len(self.Graph)+1):\n",
    "        delta = self.Graph[-i].backProp(gradient = delta,learn_rate = learn_rate)\n",
    "     \n",
    "      return True\n",
    "\n",
    "  def fit(self,input_,lables,learn_rate,batch_size,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for k,(x,y) in enumerate(zip(input_,lables)):\n",
    "            self.backProp(x,y,learn_rate)\n",
    "            if((k+1)%batch_size == 0):\n",
    "#                 print(\"after batch ends\")\n",
    "                self.update(learn_rate)\n",
    "#         print(\"after epoch ends\")\n",
    "        self.update(learn_rate)\n",
    "        \n",
    "  def update(self,learn_rate):\n",
    "#     print(\"from update\")\n",
    "    for i in self.Graph:\n",
    "        \n",
    "        i.update(learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oIn4dLb1NZF"
   },
   "outputs": [],
   "source": [
    "class cnn():\n",
    "  def __init__(self,input_shape,num_filters,filter_size):\n",
    "    self.num_filters = num_filters\n",
    "    self.filter_size = filter_size\n",
    "    self.input_shape = input_shape\n",
    "    self.conv_filters = np.random.randn(num_filters,filter_size,filter_size)/(filter_size*filter_size)\n",
    "  def forwardProp(self,image):\n",
    "    height, width = image.shape\n",
    "    self.conv_out= np.zeros((self.num_filters,(height - self.filter_size + 1) ,(width - self.filter_size + 1 )))\n",
    "    for image_patch,j,i in self.image_region(image):\n",
    "      for k in range(self.num_filters):\n",
    "        if (np.sum(image_patch * self.conv_filters[k] ,axis=(0,1))<0) : \n",
    "          self.conv_out[k,j,i] = 0\n",
    "        else: \n",
    "          self.conv_out[k,j,i] = np.sum(image_patch * self.conv_filters[k] ,axis=(0,1))\n",
    "    for i in range(self.num_filters):\n",
    "      plt.imshow(self.conv_out[i,:,:],cmap='gray')\n",
    "      plt.show()    \n",
    "\n",
    "    return self.conv_out\n",
    "  def image_region(self,image,filter_=None):\n",
    "    if filter_ is None:\n",
    "      filter_size = self.filter_size\n",
    "    else:\n",
    "      filter_size = filter_.shape[1]\n",
    "    self.image = image\n",
    "    hight,width = image.shape\n",
    "    for i in range(hight- filter_size+1):\n",
    "      for j in range(width-filter_size+1):\n",
    "        image_patch = image[i:(i+filter_size),j:(j+filter_size)]\n",
    "        yield image_patch,i,j\n",
    "  def output_shape(self,input_shape,filter_size,num_filters):\n",
    "    if(len(input_shape) == 2):\n",
    "      return (num_filters,(input_shape[-2]-filter_size + 1 ),(input_shape[-1]-filter_size+1))\n",
    "    elif(len(input_shape) == 3):\n",
    "      return (num_filters * input_shape[0],(input_shape[-2]-filter_size+1),(input_shape[-1]-filter_size+1))\n",
    "    \"\"\" def backProp(self,gradient,learn_rate):\n",
    "    self.dl_dout = np.zeros(self.input_shape)\n",
    "    self.dl_d_filter = np.zeros(self.conv_filters.shape)\n",
    "    for image_patch,j,i in self.image_region(image,gradient):\n",
    "      for k in range(self.num_filters):\n",
    "        self.dl_d_filter[k,i,j] = np.sum(image_patch*gradient[k] ,axis = (0,1) )  \n",
    "      \n",
    "    self.conv_filters = np.array([f-learn_rate*(nf/np.amax(nf,axis=(0,1))) for f,nf in zip(self.conv_filters,self.dl_d_filter)])\n",
    "   for k in range(self.num_filters):\n",
    "      self.conv_filters = self.conv_filters/np.amax(self.conv_filters,axis=(0,1))\"\"\"\n",
    "\n",
    "  def backProp(self,gradient,learn_rate):\n",
    "    dl_d_conv = np.zeros(self.conv_filters.shape)\n",
    "    \"\"\"    \n",
    "    for image_patch,i,j in self.image_region(self.image):\n",
    "      for k in range(self.num_filters):\n",
    "        dl_d_conv[k] += image_patch*gradient[k,i,j]\n",
    "    self.conv_filters -=  learn_rate*dl_d_conv   \n",
    "   \"\"\"\n",
    "\n",
    "    for k in range(gradient.shape[0]):   # On parcourt tous les filtres\n",
    "      for i in range(self.filter_size): # indices du rÃ©sultat\n",
    "        for j in range(self.filter_size):\n",
    "          for l in range(gradient.shape[1]):\n",
    "            for c in range(gradient.shape[2]): \n",
    "              dl_d_conv[k,i,j] += (gradient[k,l,c] * self.image[ i+l, j+c])\n",
    "    self.conv_filters = np.array([w-(learn_rate * nw)\n",
    "                          for w,nw in zip(self.conv_filters,dl_d_conv)]).reshape(self.conv_filters.shape)\n",
    "#     print(dl_d_conv)\n",
    "    return self.conv_filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mO06iFI01Var"
   },
   "outputs": [],
   "source": [
    "class maxPool():\n",
    "  def __init__(self,input_shape,filter_size):\n",
    "    self.filter_size = filter_size\n",
    "    self.num_filters = input_shape[0]\n",
    "    self.input_shape = input_shape\n",
    "  def output_shape(self,input_shape,filter_size,num_filters):\n",
    "      return (num_filters ,(input_shape[-2]//filter_size ),(input_shape[-1]//filter_size))\n",
    "  def image_region(self,image):\n",
    "    self.image = image\n",
    "    hight = image.shape[1]//self.filter_size\n",
    "    width = image.shape[2]//self.filter_size\n",
    "    for k in range(self.num_filters):\n",
    "      for i in range(hight):\n",
    "        for j in range(width):\n",
    "          image_patch = image[k,(i*self.filter_size):(i*self.filter_size+self.filter_size),(j*self.filter_size):(j*self.filter_size+self.filter_size)]\n",
    "          yield image_patch,k,i,j\n",
    "  def forwardProp(self,image):\n",
    "    num_filters,hight,width= image.shape\n",
    "    self.output = np.zeros((num_filters,hight // self.filter_size, width // self.filter_size  ))\n",
    "    for image_patch,k,i,j in self.image_region(image):\n",
    "      self.output[k][i][j] = np.amax(image_patch,axis=(0,1))\n",
    "    return self.output\n",
    "  def backProp(self,gradient,learn_rate):\n",
    "    self.dl_dout = np.zeros(self.image.shape)\n",
    "    for image_patch,k,i,j in self.image_region(self.image):\n",
    "      hight,width = image_patch.shape\n",
    "      max_val = np.amax(image_patch,axis=(0,1))\n",
    "      for i1 in range(hight):\n",
    "        for j1 in range(width):\n",
    "          if(max_val == image_patch[i1,j1]):\n",
    "            \n",
    "            self.dl_dout[k,i*self.filter_size+i1,j*self.filter_size+j1] = gradient[k,i,j]\n",
    "#     print(self.dl_dout.shape[0])\n",
    "\n",
    "    return self.dl_dout  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterAvgPool():\n",
    "  def __init__(self,input_shape,filter_size):\n",
    "    self.filter_size = filter_size\n",
    "    self.num_filters = input_shape[0]\n",
    "    self.input_shape = input_shape\n",
    "  def output_shape(self,input_shape,filter_size,num_filters):\n",
    "      return (num_filters ,(input_shape[-2]//filter_size ),(input_shape[-1]//filter_size))\n",
    "  def image_region(self,image):\n",
    "    self.image = image\n",
    "    hight = image.shape[1]//self.filter_size\n",
    "    width = image.shape[2]//self.filter_size\n",
    "    for k in range(self.num_filters):\n",
    "      for i in range(hight):\n",
    "        for j in range(width):\n",
    "          image_patch = image[k,(i*self.filter_size):(i*self.filter_size+self.filter_size),(j*self.filter_size):(j*self.filter_size+self.filter_size)]\n",
    "          yield image_patch,k,i,j\n",
    "  def forwardProp(self,image):\n",
    "    num_filters,hight,width= image.shape\n",
    "    self.output = np.zeros((num_filters,hight // self.filter_size, width // self.filter_size  ))\n",
    "    for image_patch,k,i,j in self.image_region(image):\n",
    "      self.output[k][i][j] = np.amax(image_patch,axis=(0,1))\n",
    "    return self.output\n",
    "  def backProp(self,gradient,learn_rate):\n",
    "    self.dl_dout = np.zeros(self.image.shape)\n",
    "    for image_patch,k,i,j in self.image_region(self.image):\n",
    "      hight,width = image_patch.shape\n",
    "      max_val = np.amax(image_patch,axis=(0,1))\n",
    "      for i1 in range(hight):\n",
    "        for j1 in range(width):\n",
    "          if(max_val == image_patch[i1,j1]):\n",
    "            \n",
    "            self.dl_dout[k,i*self.filter_size+i1,j*self.filter_size+j1] = gradient[k,i,j]\n",
    "#     print(self.dl_dout.shape[0])\n",
    "\n",
    "    return self.dl_dout  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SlRpaUM31ZE1"
   },
   "outputs": [],
   "source": [
    "class dense():\n",
    "  def __init__(self,input_shape,output_size):\n",
    "    if(len(input_shape) == 1):\n",
    "      self.input_shape = input_shape[0]\n",
    "    else: \n",
    "      self.input_shape = 1\n",
    "      for i in input_shape:\n",
    "        self.input_shape *= i \n",
    "      \n",
    "    self.inp_origin_shape = input_shape\n",
    "    self.num_filters = 0\n",
    "    self.filter_size = 0\n",
    "    self.output_size = output_size\n",
    "    self.weights = np.random.randn(self.input_shape,output_size)\n",
    "    self.biases = np.random.randn((self.output_size))\n",
    "    self.db = np.zeros(self.biases.shape)\n",
    "    self.dw = np.zeros(self.weights.shape)\n",
    "  def output_shape(self,input_shape,filter_size,num_filters):\n",
    "    #ccomputing the ouput shape to sett up the operations graph\n",
    "    return (self.output_size,)\n",
    "  def forwardProp(self,input_):\n",
    "    if (input_.shape != self.inp_origin_shape):\n",
    "      raise ValueError(\"input shape doesn't match the sepicified 1 \")\n",
    "    self.inp= input_.flatten()\n",
    "    self.al = np.dot(self.inp , self.weights)+self.biases\n",
    "    self.zl = self.segmoid(self.al)\n",
    "    self.out = self.zl\n",
    "    return self.out\n",
    "  def segmoid(self,x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "  def segmoid_prime(self,x):\n",
    "    return self.segmoid(x)*(1-self.segmoid(x))\n",
    "  def backProp(self,learn_rate,lable = None, gradient = None):\n",
    "    # gradient is the returned value of the next layer during back propagation \n",
    "    # it the derivation with respect to the activation \n",
    "\n",
    "    if gradient is not None:\n",
    "      self.gradient = gradient\n",
    "    elif lable is not None:\n",
    "      self.gradient = self.zl - lable\n",
    "    else:\n",
    "      raise ValueError(\"No gradient No lable\")\n",
    "    # self.db is the error with respect to biases of this layer \n",
    "    # self.dw is the error with respect to weights of this layer \n",
    "#     self.db = self.gradient * self.segmoid_prime(self.al)\n",
    "#     self.dw = np.outer(self.inp,self.db)\n",
    "    delta = self.gradient * self.segmoid_prime(self.al)\n",
    "    self.db =self.db + delta\n",
    "    self.dw =self.dw + np.outer(self.inp,delta)\n",
    "    self.dal_1 = delta@np.array(self.weights).transpose()\n",
    "    # updating weights an biases \n",
    "#     self.weights = np.array([w-(learn_rate * nw)\n",
    "#                           for w,nw in zip(self.weights,self.dw)]).reshape(self.weights.shape)\n",
    "#     self.biases = np.array([b-(learn_rate * nb)\n",
    "#                           for b,nb in zip(self.biases,self.db)]).reshape(self.biases.shape)\n",
    "#     self.weights = np.array([w-(learn_rate * nw)\n",
    "#                           for w,nw in zip(self.weights,self.dw)]).reshape(self.weights.shape)\n",
    "#     self.biases = np.array([b-(learn_rate * nb)\n",
    "#                           for b,nb in zip(self.biases,self.db)]).reshape(self.biases.shape)\n",
    "    \n",
    "    return self.dal_1.reshape(self.inp_origin_shape)\n",
    "  def update(self,learn_rate):\n",
    "    self.weights = np.array([w-(learn_rate * nw)\n",
    "                          for w,nw in zip(self.weights,self.dw)]).reshape(self.weights.shape)\n",
    "    self.biases = np.array([b-(learn_rate * nb)\n",
    "                          for b,nb in zip(self.biases,self.db)]).reshape(self.biases.shape)\n",
    "    self.db = np.zeros(self.biases.shape)\n",
    "    self.dw = np.zeros(self.weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjX0TD5B2WUA"
   },
   "outputs": [],
   "source": [
    "cnn1 = sequential()\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_hHQ2tXF3hnF",
    "outputId": "08c04cb0-e009-45b8-c093-457c71baf777"
   },
   "outputs": [],
   "source": [
    "cnn1.add(cnn1.cnn(num_filters=3,filter_size = 3,input_shape = (224,224)))\n",
    "cnn1.add(cnn1.max_pool(num_filters=8,filter_size=2))\n",
    "cnn1.add(cnn1.dense(1000))\n",
    "cnn1.add(cnn1.dense(1))\n",
    "for i in range(200):\n",
    "  cnn1.backProp(input_= image,lable= 1,learn_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOz_Cr7V1eZb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.dense object at 0x00000224095EE438>]\n",
      "[<__main__.dense object at 0x00000224095EE438>, <__main__.dense object at 0x00000224114C6780>]\n",
      "[<__main__.dense object at 0x00000224095EE438>, <__main__.dense object at 0x00000224114C6780>, <__main__.dense object at 0x00000224113EDC18>]\n"
     ]
    }
   ],
   "source": [
    "testback = sequential()\n",
    "testback.add(testback.dense(input_shape=(3,),output_size = 2))\n",
    "testback.add(testback.dense(output_size = 5))\n",
    "testback.add(testback.dense(output_size = 3))\n",
    "data_train=np.array(([[0,0,0],\n",
    "             [1,0,0],\n",
    "             [0,1,0],\n",
    "             [1,1,0],\n",
    "             [0,0,1],\n",
    "             [1,0,1],\n",
    "             [0,1,1],\n",
    "             [1,1,1]\n",
    "             ]) ) \n",
    "lable_train = np.array(([[1,1,1],\n",
    "             [0,1,1],\n",
    "             [1,0,1],\n",
    "             [0,0,1],\n",
    "             [1,1,0],\n",
    "             [0,1,0],\n",
    "             [1,0,0],\n",
    "             [0,0,0]\n",
    "             ]) )\n",
    "# for i in range(15000):\n",
    "#   print(\"epoch =======> {} \".format(i) )\n",
    "#   for x,y in zip(data_train,lable_train):\n",
    "#     testback.backProp(x,y,learn_rate=0.01)\n",
    "\n",
    "testback.fit(data_train,lable_train,0.25,2,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6v26lqI1fdf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95030296 0.14158834 0.9507822 ]\n"
     ]
    }
   ],
   "source": [
    "print(testback.forawrdProp(np.array([0,1,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "correct_sequential.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
